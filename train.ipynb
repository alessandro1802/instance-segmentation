{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "569fe701-b13f-4bb0-abac-89a00cce8f7c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc89931-00cd-47e2-a8fb-80df93512ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c089fe-6a1d-4437-b745-07f8bc615d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3d9889-3c96-4cb6-955b-201332df56cc",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754bf80-8bb0-43eb-a53c-5832b58c10b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/\"\n",
    "BATCH_SIZE = 8\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_WIDTH = 224\n",
    "SEED = 123\n",
    "N_CLASSES = 66\n",
    "\n",
    "def getDataset(path):\n",
    "    return tf.keras.utils.image_dataset_from_directory(\n",
    "                path,\n",
    "                labels=None,\n",
    "                color_mode='rgb',\n",
    "                batch_size=BATCH_SIZE,\n",
    "                image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "                shuffle=True,\n",
    "                seed=SEED,\n",
    "                validation_split=None,\n",
    "                interpolation='bilinear',\n",
    "                crop_to_aspect_ratio=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8add896-9720-4ac1-a950-8bebbc3ec7d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x = getDataset(DATA_PATH + \"training/images\")\n",
    "train_y = getDataset(DATA_PATH + \"training/instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3b163e-a3e2-47b4-bff3-7e141fed53b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_x = getDataset(DATA_PATH + \"validation/images\")\n",
    "test_y = getDataset(DATA_PATH + \"validation/instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40bc92-14d6-49c3-a171-cbc6bd90b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.zip((train_x, train_y))\n",
    "test_ds = tf.data.Dataset.zip((test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684d9907-6104-4aad-af7a-35e52bf42f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayExample(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25c3294-0ae1-4a1d-bd7a-b08700e698ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, masks in train_ds.take(1):\n",
    "    sample_image, sample_mask = images[0], masks[0]\n",
    "    print(sample_mask.shape)\n",
    "    displayExample([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd4b5f-aadf-4859-abb9-9e73ba21f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0 # [0.0, 1.0]\n",
    "    input_mask = tf.cast(input_mask[:, :, :, 0], np.uint8) # [0, 65]\n",
    "    input_mask = tf.one_hot(input_mask, N_CLASSES) # One hot each pixel\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a31431-0683-4cd6-9c62-25c3f0681d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(normalize)\n",
    "test_ds = test_ds.map(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a145e9d-26b1-4362-be36-ab7589e2b6c7",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ea50c-feb1-4151-8204-57beccfef216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=[IMAGE_HEIGHT, IMAGE_WIDTH, 3], include_top=False)\n",
    "\n",
    "# Use the activations of these layers\n",
    "layer_names = [\n",
    "    'block_1_expand_relu',   # 64x64\n",
    "    'block_3_expand_relu',   # 32x32\n",
    "    'block_6_expand_relu',   # 16x16\n",
    "    'block_13_expand_relu',  # 8x8\n",
    "    'block_16_project',      # 4x4\n",
    "]\n",
    "base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n",
    "\n",
    "down_stack.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a98ab-f413-4dbc-b50f-532fd40c7eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "up_stack = [\n",
    "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
    "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
    "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
    "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf2eba3-d9b4-4ceb-821a-6a1051903679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unet_model(output_channels:int):\n",
    "    inputs = tf.keras.layers.Input(shape=[IMAGE_HEIGHT, IMAGE_WIDTH, 3])\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = down_stack(inputs)\n",
    "    x = skips[-1]\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        concat = tf.keras.layers.Concatenate()\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    # This is the last layer of the model\n",
    "    last = tf.keras.layers.Conv2DTranspose(\n",
    "        filters=output_channels, kernel_size=3, strides=2,\n",
    "        padding='same')  # 128x128 -> 256x256\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37d652b-d562-4613-9c38-16adc0cec34c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = unet_model(output_channels=N_CLASSES)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['categorical_accuracy', tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6e493-bb07-418f-8334-88612fa4df83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19794ca1-6b53-4ed1-8f7b-deda8072c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4071d0a-b9a5-4d92-8885-b38b0fd8e54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.math.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    if len(pred_mask.shape) > 3:\n",
    "        pred_mask = pred_mask[0]\n",
    "    return pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486bcd1c-139f-4048-8054-cb1824e5211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(dataset=None, num=1):\n",
    "    for image, mask in dataset.take(num):\n",
    "        pred_mask = create_mask(model.predict(image))\n",
    "        true_mask = create_mask(mask[0])\n",
    "        displayExample([image[0], true_mask, pred_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ae4ba9-1d51-4136-8c79-4415123e0473",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290313cd-3299-4fd4-ba91-549cb057c89b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions(train_ds)\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2ab869-d13b-4ba1-8c4e-cbea6c651cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = './models/model.h5'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    verbose=0,\n",
    "    mode='max',\n",
    "    save_freq=\"epoch\",\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76b4919-2d35-4e9d-9112-35b7e84fe1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550609ea-f219-4397-a0b2-3d8284f0608c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587862e-1ed1-4df2-add6-aac987378eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "STEPS_PER_EPOCH = 800 // BATCH_SIZE\n",
    "VAL_SUBSPLITS = 5\n",
    "VALIDATION_STEPS = 200//BATCH_SIZE//VAL_SUBSPLITS\n",
    "\n",
    "model_history = model.fit(train_ds, \n",
    "                          epochs = EPOCHS, \n",
    "                          steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                          validation_steps = VALIDATION_STEPS, \n",
    "                          validation_data = test_ds,\n",
    "                          callbacks = [DisplayCallback(), model_checkpoint_callback, early_stopping_callback])\n",
    "\n",
    "with open('./histories/history.pickle', 'wb+') as file:\n",
    "    pickle.dump(model_history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6727c04-f670-4962-b491-6b3ac560c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayLearningCurves(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Loss curves')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc = 'upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['categorical_accuracy'])\n",
    "    plt.plot(history.history['val_categorical_accuracy'])\n",
    "    plt.title('Accuracy curves')\n",
    "    plt.ylabel('Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc = 'upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0662a63-c893-435a-9f88-54bbd2835c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayLearningCurves(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a6455-8848-42b4-8c8f-eff697dc0327",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.keras.models.load_model(checkpoint_filepath)\n",
    "test.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
